{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8435e585",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pt.evaluation.pascal_voc_evaluation_copy import PascalVOCDetectionEvaluator\n",
    "#from detectron2.evaluation import PascalVOCDetectionEvaluator\n",
    "from detectron2.evaluation import inference_on_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62f7210a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/superorange5/.local/lib/python3.7/site-packages/torchvision/transforms/transforms.py:892: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
      "  \"Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. \"\n"
     ]
    }
   ],
   "source": [
    "from Nb_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b89a033",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "382c99a0",
   "metadata": {},
   "source": [
    "## setting (model path & config path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9148975",
   "metadata": {},
   "outputs": [],
   "source": [
    "DA_dataset = 'c2kb' #'c2kb'  #skf2c\n",
    "detector_name = 'ptso' #'ptda'  #'ptso'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95b471b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keep_experiments/c2b_source-only/cfg.yaml\n",
      "keep_experiments/c2b_source-only/model_0027999.pth\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Config file 'keep_experiments/c2b_source-only/cfg.yaml' does not exist!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-03253897a33a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mmodel_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_k2b\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_c2b\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdetector_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'ptso'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mmodel_c2b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_TSmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'c2b_source-only'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m27999\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mmodel_k2b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_TSmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'k2b_source-only'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7999\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mmodel_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_k2b\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_c2b\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/ProbabilisticTeacher/Nb_utils.py\u001b[0m in \u001b[0;36mwarp\u001b[0;34m(dataset_name, model_num)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwarp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/ProbabilisticTeacher/Nb_utils.py\u001b[0m in \u001b[0;36mload_TSmodel\u001b[0;34m(cfg_path, model_path)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mget_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_TSmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m     \u001b[0mcfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m     \u001b[0;31m#cfg.defrost()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;31m#cfg.MODEL.WEIGHTS = model_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/ProbabilisticTeacher/Nb_utils.py\u001b[0m in \u001b[0;36msetup\u001b[0;34m(config_file)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mcfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_cfg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0madd_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge_from_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0;31m#cfg.merge_from_list(args.opts)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/ProbabilisticTeacher/detectron2/config/config.py\u001b[0m in \u001b[0;36mmerge_from_file\u001b[0;34m(self, cfg_filename, allow_unsafe)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mallow_unsafe\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mallow\u001b[0m \u001b[0munsafe\u001b[0m \u001b[0myaml\u001b[0m \u001b[0msyntax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \"\"\"\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mPathManager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"Config file '{cfg_filename}' does not exist!\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mloaded_cfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_yaml_with_base\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_unsafe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_unsafe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mloaded_cfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloaded_cfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Config file 'keep_experiments/c2b_source-only/cfg.yaml' does not exist!"
     ]
    }
   ],
   "source": [
    "if DA_dataset == 'c2kb':\n",
    "    ratio=1.2\n",
    "    val_dataset_name = 'VOC2007_bddval1'   #'VOC2007_bddvalsmall'\n",
    "    source_list =['kitti','cityscape']\n",
    "    config_path = \"configs/pt/final_c2b.yaml\"\n",
    "    if detector_name == 'ptda':\n",
    "        model_c2b = load_TSmodel('c2b', 11999)\n",
    "        model_k2b = load_TSmodel('k2b', 'final')\n",
    "        model_list=[model_k2b,model_c2b]\n",
    "    elif detector_name == 'ptso':\n",
    "        model_c2b = load_TSmodel('c2b_source-only', 27999)\n",
    "        model_k2b = load_TSmodel('k2b_source-only', 7999)\n",
    "        model_list=[model_k2b,model_c2b]\n",
    "\n",
    "elif DA_dataset=='skf2c':    \n",
    "    val_dataset_name = 'VOC2007_cityval1'\n",
    "    source_list =['sim10k','kitti','foggycityscape']\n",
    "    ratio = 1.706\n",
    "    config_path = \"configs/pt/final_k2c.yaml\"\n",
    "    if detector_name == 'ptda':\n",
    "        model_s2c = load_TSmodel('s2c', 15999)\n",
    "        model_k2c = load_TSmodel('k2c', 19999)\n",
    "        #model_f2c = get_model('f2c', 'final') #8class\n",
    "        model_f2c = load_TSmodel('f2c_1class', 11999)\n",
    "        model_list=[model_s2c,model_k2c,model_f2c]\n",
    "    elif detector_name == 'ptso':\n",
    "        model_s2c = load_TSmodel('s2c_source-only', 23999)\n",
    "        model_k2c = load_TSmodel('k2c_source-only', 'final')\n",
    "        model_f2c = load_TSmodel('f2c_source-only', 27999)\n",
    "        model_list=[model_s2c,model_k2c,model_f2c]\n",
    "\n",
    "        \n",
    "# config\n",
    "cfg = setup_all(config_path)\n",
    "\n",
    "# load test data\n",
    "test_data_loader = build_detection_test_loader(cfg, val_dataset_name)\n",
    "evaluator = PascalVOCDetectionEvaluator(val_dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d610bcf5",
   "metadata": {},
   "source": [
    "# evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f907ef9",
   "metadata": {},
   "source": [
    "### A. inference all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b92b021",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_i = inference_on_dataset(model_to_eval, test_data_loader, evaluator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d1529af9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('bbox',\n",
       "              {'AP': 29.757639038918928,\n",
       "               'AP50': 58.169071629659264,\n",
       "               'AP75': 29.25375686697318})])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7f01e0",
   "metadata": {},
   "source": [
    "### B. inference batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "220175ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import ExitStack, contextmanager\n",
    "from torch import nn\n",
    " \n",
    "evaluator.reset()\n",
    "model_to_eval = model_list[0]\n",
    "model_to_eval.eval()\n",
    "#print(instances.pred_boxes.tensor)\n",
    "\n",
    "for idx, inputs in enumerate(test_data_loader):\n",
    "    #print(inputs)\n",
    "    #print(get_proposal_roih(inputs,model_to_eval))\n",
    "    outputs = model_to_eval.modelStudent(inputs)\n",
    "    #print(outputs[0][\"instances\"])\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "    evaluator.process_eval(inputs, outputs)\n",
    "results = evaluator.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9743e5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('bbox',\n",
       "              {'AP': 29.507701847189956,\n",
       "               'AP50': 52.372955971225146,\n",
       "               'AP75': 29.56818902766315})])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11072193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'instances': Instances(num_instances=28, image_height=1024, image_width=2048, fields=[pred_boxes: Boxes(tensor([[ 326.7519,  440.0365,  618.3756,  519.4741],\n",
       "          [   0.0000,  404.9550,  168.9063,  550.9739],\n",
       "          [1182.1501,  444.9689, 1252.7135,  496.8851],\n",
       "          [ 134.5826,  405.4463,  355.9171,  536.6377],\n",
       "          [1858.5892,   63.9379, 1954.0305,  177.9242],\n",
       "          [ 504.0312,  439.1638,  609.7053,  524.9960],\n",
       "          [ 905.1487,  442.3421, 1010.9626,  499.1852],\n",
       "          [   6.4120,  398.8298,  406.4436,  547.3654],\n",
       "          [1221.2854,  511.4424, 1292.7891,  555.7824],\n",
       "          [ 927.2269,  456.6595,  988.6171,  497.8509],\n",
       "          [1481.2874,  184.6058, 1748.6989,  292.9760],\n",
       "          [1484.6484,  184.5870, 1621.5295,  273.5999],\n",
       "          [ 953.2852,  452.2430, 1005.0145,  493.9701],\n",
       "          [ 978.5691,  437.3337, 1024.8195,  472.8095],\n",
       "          [ 514.1945,  485.8729,  576.8962,  524.5416],\n",
       "          [1152.2059,  422.3804, 1200.3099,  465.1030],\n",
       "          [1233.1779,  434.8233, 1276.1887,  474.4245],\n",
       "          [1215.6475,  419.8162, 1262.9756,  457.2830],\n",
       "          [ 550.3024,  488.4149,  604.4203,  520.4172],\n",
       "          [1238.9266,  448.5323, 1285.3552,  485.3897],\n",
       "          [1091.0183,  400.4984, 1175.3521,  458.2978],\n",
       "          [ 907.6016,  462.5006,  965.5695,  498.5154],\n",
       "          [1146.0667,  438.4634, 1193.6473,  473.9833],\n",
       "          [ 877.2275,  444.9391,  957.4338,  492.8555],\n",
       "          [ 884.0995,  441.5689,  931.2397,  478.1279],\n",
       "          [ 879.3320,  465.0398,  941.8268,  510.6342],\n",
       "          [1110.9757,  409.2378, 1171.6160,  448.8205],\n",
       "          [1133.5032,  425.8576, 1182.4852,  463.5832]], device='cuda:0',\n",
       "         grad_fn=<IndexBackward>)), scores: tensor([0.9566, 0.9477, 0.9455, 0.9410, 0.7879, 0.6284, 0.5558, 0.1708, 0.0715,\n",
       "          0.0587, 0.0586, 0.0479, 0.0445, 0.0325, 0.0287, 0.0233, 0.0200, 0.0172,\n",
       "          0.0172, 0.0171, 0.0166, 0.0133, 0.0122, 0.0114, 0.0078, 0.0066, 0.0053,\n",
       "          0.0049], device='cuda:0', grad_fn=<IndexBackward>), pred_classes: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0], device='cuda:0'), scores_logists: tensor([[ 2.8020, -2.8196],\n",
       "          [ 2.9200, -2.9213],\n",
       "          [ 2.9873, -2.9053],\n",
       "          [ 2.8300, -2.7995],\n",
       "          [ 1.2255, -1.1749],\n",
       "          [ 1.0674, -1.0463],\n",
       "          [ 0.8406, -0.7470],\n",
       "          [-0.6996,  0.6903],\n",
       "          [-1.1890,  1.2149],\n",
       "          [-0.7188,  0.7258],\n",
       "          [-0.9608,  0.9957],\n",
       "          [-1.0761,  1.1189],\n",
       "          [-0.8408,  0.8719],\n",
       "          [-0.8770,  0.8705],\n",
       "          [-1.1922,  1.1639],\n",
       "          [-1.0344,  0.9967],\n",
       "          [-1.0755,  1.0560],\n",
       "          [-1.2907,  1.2614],\n",
       "          [-1.3067,  1.3288],\n",
       "          [-1.4022,  1.4074],\n",
       "          [-1.2834,  1.2342],\n",
       "          [-1.2860,  1.2943],\n",
       "          [-1.2445,  1.2230],\n",
       "          [-1.2927,  1.2861],\n",
       "          [-1.3842,  1.4003],\n",
       "          [-1.3572,  1.4138],\n",
       "          [-1.4742,  1.4558],\n",
       "          [-1.4547,  1.4566]], device='cuda:0', grad_fn=<IndexBackward>), boxes_sigma: tensor([[-3.4695, -3.3773, -3.1068, -2.8675],\n",
       "          [-2.9253, -3.0999, -2.8106, -3.0032],\n",
       "          [-3.5701, -2.6831, -3.1864, -2.4932],\n",
       "          [-2.7551, -3.0716, -2.4751, -3.1553],\n",
       "          [-2.2692, -1.7291, -1.8032, -1.5371],\n",
       "          [-0.3720, -1.8721,  0.1297, -2.0987],\n",
       "          [-0.2799, -2.0620,  0.3208, -1.3881],\n",
       "          [-1.4354, -3.4896, -0.9385, -2.5751],\n",
       "          [-2.1421, -1.6904, -1.9962, -1.6098],\n",
       "          [ 1.9686,  0.6029,  1.4642, -0.2670],\n",
       "          [-0.3637,  0.1665,  0.0685,  0.5700],\n",
       "          [ 0.6452, -0.9203,  0.8398, -0.1983],\n",
       "          [ 3.4396,  0.0128,  3.4527, -0.4334],\n",
       "          [ 1.9664,  0.9012,  2.0648,  0.6116],\n",
       "          [-0.1016,  2.2562, -0.1844,  1.6529],\n",
       "          [ 1.6028,  1.3641,  1.5693,  1.0434],\n",
       "          [ 2.4569,  1.3118,  1.9944,  0.6569],\n",
       "          [ 1.3479,  1.4696,  0.9219,  0.9742],\n",
       "          [ 0.9244,  1.3555,  0.8733,  1.1365],\n",
       "          [ 2.1898,  0.2907,  1.8864, -0.1748],\n",
       "          [ 2.4192,  0.5839,  2.0902,  0.6741],\n",
       "          [ 3.0480,  1.1069,  2.4827,  0.4610],\n",
       "          [ 1.9071,  1.6381,  1.7562,  1.4679],\n",
       "          [ 3.2723,  0.7395,  3.3670,  1.0936],\n",
       "          [ 1.9484,  1.6765,  2.2401,  1.6550],\n",
       "          [ 2.3890,  1.8064,  2.2806,  1.8858],\n",
       "          [ 3.2793,  1.7646,  2.9766,  1.4427],\n",
       "          [ 2.6219,  2.0273,  2.5625,  1.9886]], device='cuda:0',\n",
       "         grad_fn=<IndexBackward>)])}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085198cd",
   "metadata": {},
   "source": [
    "## pseudo-label generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebc50ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def get_match_array_nogt(proposals_roih):\n",
    "        source_num = len(proposals_roih)\n",
    "        batch_size = len(proposals_roih[0])\n",
    "\n",
    "        batch_match_array= []\n",
    "        for data_idx in range(batch_size):\n",
    "            match_array_source = []\n",
    "            for i, source_prediction_n in enumerate(proposals_roih):\n",
    "                match_array_source_n =[]\n",
    "                # others\n",
    "                #pairwise_sa_sb = []        \n",
    "                for j in range(source_num):\n",
    "                    if j!=i:\n",
    "                        sourcen_n_match_other = structures.pairwise_iou(source_prediction_n[data_idx].get('pred_boxes'),proposals_roih[j][data_idx].get('pred_boxes'))\n",
    "                        #pairwise_sa_sb.append(sourcen_n_match_other)\n",
    "                        match_array_source_n.append(get_match_array(sourcen_n_match_other))\n",
    "                match_array_source.append(match_array_source_n)\n",
    "            batch_match_array.append(match_array_source)\n",
    "\n",
    "        return  batch_match_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "191c565c",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def bb_ensemble(mt_src,src_idx):\n",
    "        source_num = len(mt_src[0])\n",
    "        df_src = pd.DataFrame()    \n",
    "        src_array = np.array(mt_src[src_idx]).T\n",
    "        df_src = pd.DataFrame(src_array)\n",
    "        df_src['summary'] = df_src.sum(axis=1)\n",
    "        keep_index = df_src.index[df_src.summary==source_num]\n",
    "        return keep_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "beb25c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def process_pseudo_label2(proposals_roih):\n",
    "        list_instances = []\n",
    "        for proposal_bbox_inst in proposals_roih:\n",
    "\n",
    "            image_shape = proposal_bbox_inst.image_size\n",
    "            new_proposal_inst = FreeInstances(image_shape)\n",
    "\n",
    "            new_bbox_loc = proposal_bbox_inst.pred_boxes.tensor\n",
    "            pseudo_boxes = Boxes(new_bbox_loc)\n",
    "\n",
    "            # add boxes to instances\n",
    "            \n",
    "            new_proposal_inst.pseudo_boxes = pseudo_boxes\n",
    "            new_proposal_inst.scores_logists = proposal_bbox_inst.scores_logists\n",
    "            new_proposal_inst.scores = proposal_bbox_inst.scores\n",
    "            new_proposal_inst.pred_classes = proposal_bbox_inst.pred_classes\n",
    "\n",
    "            \n",
    "            if proposal_bbox_inst.has('boxes_sigma'):\n",
    "                new_proposal_inst.boxes_sigma = proposal_bbox_inst.boxes_sigma\n",
    "            list_instances.append(new_proposal_inst)\n",
    "        return list_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "442ac39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_return_proposal(proposal_roih,ratio):\n",
    "    scale_pred = proposal_roih[0].get('pred_boxes')\n",
    "    scale_pred.scale(ratio,ratio)\n",
    "    proposal_roih[0].pred_boxes=scale_pred\n",
    "    return proposal_roih"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf3452d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d89ca75",
   "metadata": {},
   "outputs": [],
   "source": [
    "_SRC_IDX = 1#  0:s  1:k 2:foggy, 0:k 1:c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "522c738b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pt.structures.instances import FreeInstances\n",
    "\n",
    "#data_loader_iter = iter(test_data_loader)\n",
    "#test_data = data_loader_iter.next()\n",
    "\n",
    "\n",
    "# change to training mode\n",
    "for model in model_list:\n",
    "    model.train()\n",
    "    \n",
    "    \n",
    "evaluator.reset()\n",
    "\n",
    "for idx, test_data in enumerate(test_data_loader):\n",
    "    #print(idx)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        roih_list = []\n",
    "        for model in model_list:\n",
    "            ( _, proposals_rpn_unsup_k, proposals_roih_unsup_k, _,) = model.modelStudent(test_data, branch=\"unsup_data_weak\")\n",
    "            roih_list.append(proposals_roih_unsup_k)\n",
    "            \n",
    "        batch_size = len(roih_list[0])\n",
    "        mt_src = get_match_array_nogt(roih_list)\n",
    "\n",
    "\n",
    "\n",
    "        pesudo_proposals_roih_combined = []\n",
    "        for batch_idx in range(batch_size):\n",
    "            keep_index = bb_ensemble(mt_src[batch_idx],_SRC_IDX)\n",
    "            \n",
    "            pesudo_proposals_roih_combined.append(roih_list[_SRC_IDX][batch_idx][keep_index])\n",
    "        pesudo_proposals_roih_combined_scaled = scale_return_proposal(pesudo_proposals_roih_combined,ratio)\n",
    "        pesudo_proposals_roih_combined_final = process_pseudo_label2(pesudo_proposals_roih_combined_scaled)\n",
    "        \n",
    "        evaluator.process_train(test_data, pesudo_proposals_roih_combined_final)\n",
    "results = evaluator.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4b823ba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('bbox',\n",
       "              {'AP': 31.479858580220387,\n",
       "               'AP50': 52.231894248329205,\n",
       "               'AP75': 32.95418627309308})])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9aa78f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "proposals_roih_unsup_k[0].get('pseudo_boxes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fc890a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "instances = pesudo_proposals_roih_combined_final[0].to(torch.device(\"cpu\"))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79bb16ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes = instances.pseudo_boxes.tensor.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fce4311d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = instances.scores.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "14956880",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = instances.pred_classes.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "33ca82c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Boxes(tensor([[2.0703e+02, 2.5250e+02, 3.5305e+02, 3.0611e+02],\n",
       "        [6.9360e+02, 2.6129e+02, 7.3344e+02, 2.9227e+02],\n",
       "        [2.3941e+01, 2.2972e+02, 2.0330e+02, 3.1684e+02],\n",
       "        [5.6760e-01, 2.3787e+02, 9.7256e+01, 3.2250e+02],\n",
       "        [5.2475e+02, 2.5986e+02, 5.9003e+02, 2.8800e+02],\n",
       "        [3.0422e+02, 2.5544e+02, 3.5472e+02, 3.0591e+02],\n",
       "        [6.7413e+02, 2.5055e+02, 7.0496e+02, 2.7166e+02],\n",
       "        [5.1500e+02, 2.6150e+02, 5.5781e+02, 2.8730e+02],\n",
       "        [6.7304e+02, 2.3496e+02, 7.0752e+02, 2.6571e+02],\n",
       "        [6.7183e+02, 2.5848e+02, 6.9716e+02, 2.7603e+02],\n",
       "        [6.6311e+02, 2.5212e+02, 6.9341e+02, 2.7043e+02],\n",
       "        [7.1064e+02, 2.4688e+02, 7.4932e+02, 2.7358e+02],\n",
       "        [6.5555e+02, 2.5004e+02, 6.8373e+02, 2.6945e+02]]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instances.pseudo_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "18479265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.975 208.0 253.5 353.0 306.1\n",
      " 0.968 694.6 262.3 733.4 292.3\n",
      " 0.951 24.9 230.7 203.3 316.8\n",
      " 0.936 1.6 238.9 97.3 322.5\n",
      " 0.890 525.7 260.9 590.0 288.0\n",
      " 0.124 305.2 256.4 354.7 305.9\n",
      " 0.040 675.1 251.5 705.0 271.7\n",
      " 0.016 516.0 262.5 557.8 287.3\n",
      " 0.015 674.0 236.0 707.5 265.7\n",
      " 0.013 672.8 259.5 697.2 276.0\n",
      " 0.012 664.1 253.1 693.4 270.4\n",
      " 0.009 711.6 247.9 749.3 273.6\n",
      " 0.006 656.5 251.0 683.7 269.4\n"
     ]
    }
   ],
   "source": [
    "for box, score, cls in zip(boxes, scores, classes):\n",
    "    xmin, ymin, xmax, ymax = box\n",
    "    # The inverse of data loading logic in `datasets/pascal_voc.py`\n",
    "    xmin += 1\n",
    "    ymin += 1\n",
    "    print(f\" {score:.3f} {xmin:.1f} {ymin:.1f} {xmax:.1f} {ymax:.1f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026d1193",
   "metadata": {},
   "source": [
    "# draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3782e108",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = setup(\"configs/pt/final_k2c.yaml\")\n",
    "dataset_name = 'VOC2007_cityval1'\n",
    "test_data_loader = build_detection_test_loader(cfg, dataset_name)\n",
    "for test_data in test_data_loader:\n",
    "    target_metadata = MetadataCatalog.get(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e2c361c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "namespace(name='VOC2007_cityval1',\n",
       "          thing_classes=['car'],\n",
       "          dirname='data/VOC2007_cityval',\n",
       "          year=2012,\n",
       "          split='val',\n",
       "          evaluator_type='pascal_voc')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "496aedcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "bboxes_to_draw = instances.pseudo_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e222e3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "54667fe1",
   "metadata": {},
   "source": [
    "drawbb(test_data[0]['file_name'], target_metadata, bboxes_to_draw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bf8b463a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreeInstances(num_instances=0, image_height=600, image_width=1200, fields=[pseudo_boxes: Boxes(tensor([], size=(0, 4))), scores_logists: tensor([], size=(0, 2)), scores: tensor([]), pred_classes: tensor([], dtype=torch.int64), boxes_sigma: tensor([], size=(0, 4))])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pesudo_proposals_roih_combined_final[0].to(torch.device(\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4c8b21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader_iter = iter(test_data_loader)\n",
    "test_data = data_loader_iter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77205b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_to_eval = model_list[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c2dc11",
   "metadata": {},
   "source": [
    "* eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "88d0abd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_to_eval.eval()\n",
    "outputs = model_to_eval.modelStudent(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "53a84b33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'instances': Instances(num_instances=48, image_height=1024, image_width=2048, fields=[pred_boxes: Boxes(tensor([[ 146.5441,  385.5511,  448.0932,  536.4307],\n",
       "          [1564.1633,  259.5304, 2048.0000,  777.3774],\n",
       "          [1327.8706,  367.4927, 1659.8536,  568.8884],\n",
       "          [1123.5928,  396.8085, 1204.7588,  453.3437],\n",
       "          [ 836.7784,  392.7728,  934.2477,  448.4558],\n",
       "          [   0.0000,  362.3156,   79.4561,  587.6072],\n",
       "          [ 696.6040,  368.8929,  784.0499,  442.3494],\n",
       "          [1329.2783,  380.4111, 1444.3099,  543.8692],\n",
       "          [1087.3569,  396.1790, 1141.2621,  445.6662],\n",
       "          [ 763.1310,  375.6651,  825.3677,  435.2816],\n",
       "          [ 120.4234,  343.5369,  211.7279,  433.3838],\n",
       "          [1048.1008,  367.9299, 1106.7754,  426.8610],\n",
       "          [1586.8948,  369.6127, 1912.4065,  733.5382],\n",
       "          [1360.7120,  247.0661, 1407.4061,  296.7185],\n",
       "          [ 106.8375,  313.8461,  212.4159,  482.0017],\n",
       "          [ 971.8511,  392.9136, 1041.5619,  426.9579],\n",
       "          [1624.3870,  271.6082, 2048.0000,  554.2144],\n",
       "          [1062.6971,  379.7148, 1119.2686,  433.5119],\n",
       "          [1318.3535,  348.6099, 1808.3481,  655.1497],\n",
       "          [ 677.3979,  408.3010,  725.5827,  443.8281],\n",
       "          [ 818.1119,  388.5790,  862.9489,  435.7765],\n",
       "          [1087.6068,  380.7898, 1144.5126,  428.9295],\n",
       "          [ 764.6998,  400.7947,  814.4288,  437.9848],\n",
       "          [ 957.0221,  398.1340, 1033.4442,  441.9272],\n",
       "          [ 678.9751,  371.7112,  729.3854,  437.6674],\n",
       "          [ 647.4544,  308.9602,  681.1641,  339.7259],\n",
       "          [1001.7162,  380.4281, 1053.6807,  415.0705],\n",
       "          [ 638.5580,  317.9996,  678.5712,  351.7123],\n",
       "          [1201.7400,  312.1512, 1983.4127,  794.5657],\n",
       "          [1188.8352,  391.0390, 1264.2590,  438.4906],\n",
       "          [ 418.2947,  374.7786,  492.9520,  444.8807],\n",
       "          [1187.6022,  386.8799, 1238.6660,  427.9277],\n",
       "          [1347.5054,  219.7729, 1404.6652,  298.0750],\n",
       "          [ 610.5123,  318.3982,  647.3408,  353.0381],\n",
       "          [2042.5852,  824.9836, 2048.0000,  902.7590],\n",
       "          [1214.0536,  306.5597, 1262.5217,  345.9127],\n",
       "          [ 486.2643,  371.4440,  547.2556,  412.0329],\n",
       "          [ 599.8493,  312.1250,  627.6063,  339.4311],\n",
       "          [ 302.5650,  314.8875,  359.4252,  369.7619],\n",
       "          [ 374.3764,  302.7377,  431.0298,  358.3094],\n",
       "          [ 393.7856,  300.7476,  435.5245,  340.5974],\n",
       "          [ 999.3268,  387.9289, 1061.1118,  427.9349],\n",
       "          [1491.8055,  292.5096, 1543.0326,  318.0611],\n",
       "          [1471.4534,  281.3358, 1528.5592,  322.5254],\n",
       "          [ 639.7087,  413.7565,  683.7016,  441.4757],\n",
       "          [1458.2858,  286.2299, 1513.9066,  318.8265],\n",
       "          [1372.5143,  257.9590, 1416.6089,  304.7912],\n",
       "          [2045.8846,  836.3521, 2048.0000,  905.8281]], device='cuda:0',\n",
       "         grad_fn=<IndexBackward>)), scores: tensor([0.9896, 0.9788, 0.9741, 0.9658, 0.9640, 0.9374, 0.9211, 0.9134, 0.9056,\n",
       "          0.8670, 0.8262, 0.7647, 0.5630, 0.1194, 0.1167, 0.0587, 0.0585, 0.0536,\n",
       "          0.0536, 0.0522, 0.0448, 0.0442, 0.0348, 0.0340, 0.0339, 0.0326, 0.0323,\n",
       "          0.0317, 0.0304, 0.0275, 0.0264, 0.0249, 0.0196, 0.0190, 0.0180, 0.0177,\n",
       "          0.0174, 0.0167, 0.0156, 0.0153, 0.0147, 0.0147, 0.0129, 0.0123, 0.0106,\n",
       "          0.0096, 0.0094, 0.0084], device='cuda:0', grad_fn=<IndexBackward>), pred_classes: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         device='cuda:0'), scores_logists: tensor([[ 4.1109, -4.1053],\n",
       "          [ 3.3923, -3.3429],\n",
       "          [ 3.3251, -3.3024],\n",
       "          [ 3.5819, -3.6083],\n",
       "          [ 3.5099, -3.4854],\n",
       "          [ 3.2486, -3.1805],\n",
       "          [ 3.5458, -3.5446],\n",
       "          [ 2.3359, -2.2683],\n",
       "          [ 2.2358, -2.2342],\n",
       "          [ 1.8329, -1.7938],\n",
       "          [ 1.6476, -1.5562],\n",
       "          [ 1.9167, -1.9105],\n",
       "          [ 0.4793, -0.5081],\n",
       "          [-0.5082,  0.5633],\n",
       "          [-0.4607,  0.4784],\n",
       "          [-0.9142,  0.8747],\n",
       "          [-1.0283,  1.1049],\n",
       "          [-0.5812,  0.5425],\n",
       "          [-1.0329,  1.0037],\n",
       "          [-0.8506,  0.8260],\n",
       "          [-1.2296,  1.1712],\n",
       "          [-1.1804,  1.1567],\n",
       "          [-1.2216,  1.2250],\n",
       "          [-1.3761,  1.4357],\n",
       "          [-1.2241,  1.2188],\n",
       "          [-1.0753,  1.0387],\n",
       "          [-1.1222,  1.0777],\n",
       "          [-0.7433,  0.7356],\n",
       "          [-0.7341,  0.6733],\n",
       "          [-1.1892,  1.1906],\n",
       "          [-1.2896,  1.2663],\n",
       "          [-1.1294,  1.0998],\n",
       "          [-1.3428,  1.3925],\n",
       "          [-1.1451,  1.1952],\n",
       "          [-0.9580,  0.9238],\n",
       "          [-1.3562,  1.3505],\n",
       "          [-1.2528,  1.2562],\n",
       "          [-1.4031,  1.3827],\n",
       "          [-1.2868,  1.2609],\n",
       "          [-1.3027,  1.3093],\n",
       "          [-1.4230,  1.4305],\n",
       "          [-1.3922,  1.3211],\n",
       "          [-1.4042,  1.3760],\n",
       "          [-1.3990,  1.3654],\n",
       "          [-1.3090,  1.3395],\n",
       "          [-1.4518,  1.4103],\n",
       "          [-1.3988,  1.4863],\n",
       "          [-1.0051,  0.9650]], device='cuda:0', grad_fn=<IndexBackward>), boxes_sigma: tensor([[-4.9760e+00, -4.5310e+00, -4.7656e+00, -4.2040e+00],\n",
       "          [-4.3229e+00, -4.1106e+00, -3.9357e+00, -3.4127e+00],\n",
       "          [-3.7046e+00, -4.0178e+00, -3.3402e+00, -3.7690e+00],\n",
       "          [-3.5837e+00, -3.2419e+00, -3.3129e+00, -3.3435e+00],\n",
       "          [-3.4506e+00, -3.2766e+00, -3.3546e+00, -3.1878e+00],\n",
       "          [-2.7876e+00, -3.0952e+00, -2.4055e+00, -2.7431e+00],\n",
       "          [-2.2881e+00, -3.1442e+00, -1.8175e+00, -3.1917e+00],\n",
       "          [-2.4131e+00, -2.9329e+00, -1.9318e+00, -2.9293e+00],\n",
       "          [-2.7512e+00, -2.4431e+00, -2.1604e+00, -2.2805e+00],\n",
       "          [-2.3697e+00, -2.1715e+00, -1.6513e+00, -2.3013e+00],\n",
       "          [-2.1886e+00, -1.8937e+00, -1.5939e+00, -1.6532e+00],\n",
       "          [-1.2004e+00, -1.7085e+00, -7.5700e-01, -1.5821e+00],\n",
       "          [-7.0586e-01, -1.7656e+00, -9.8687e-01, -1.6521e+00],\n",
       "          [-3.9212e-01,  3.3399e-01, -2.0634e-02,  6.0655e-01],\n",
       "          [ 8.2451e-01, -1.4708e-01,  1.0819e+00, -2.6711e-01],\n",
       "          [ 1.9759e+00, -1.0167e+00,  1.8762e+00, -6.2150e-01],\n",
       "          [-2.2089e+00,  7.3266e-01, -1.6261e+00,  1.7390e+00],\n",
       "          [ 3.0190e+00,  9.1439e-01,  2.3444e+00,  1.8590e-01],\n",
       "          [ 5.7145e-01, -9.7130e-01,  8.7282e-01,  9.7804e-02],\n",
       "          [ 5.1727e-01,  1.1871e+00,  5.5351e-01,  6.0710e-01],\n",
       "          [ 6.4069e-01, -8.2653e-01,  6.2719e-01, -1.1812e+00],\n",
       "          [-2.8852e-01,  4.9632e-01, -3.4148e-01,  1.1241e-01],\n",
       "          [-1.8625e-01,  1.0946e+00, -1.3054e-01,  3.4457e-01],\n",
       "          [ 9.4284e-03, -1.2304e+00,  9.7749e-02, -6.2860e-01],\n",
       "          [ 1.0610e+00, -1.5831e-01,  1.1456e+00, -6.5574e-01],\n",
       "          [ 8.0939e-01,  6.6106e-01,  9.5191e-01,  9.2155e-01],\n",
       "          [ 1.6413e+00,  2.0685e-01,  1.3428e+00,  9.2835e-02],\n",
       "          [ 2.2551e+00,  1.0918e+00,  2.2345e+00,  1.1560e+00],\n",
       "          [ 2.7070e+00,  4.2969e-01,  3.2471e+00,  1.9446e+00],\n",
       "          [ 1.5016e+00,  4.1424e-03,  1.4935e+00,  2.6903e-01],\n",
       "          [ 1.2066e+00, -2.7445e-01,  1.2211e+00,  2.4759e-01],\n",
       "          [ 1.3059e+00,  1.0443e+00,  1.2269e+00,  7.2889e-01],\n",
       "          [ 2.5656e-01,  8.3439e-01,  7.9046e-01,  1.1601e+00],\n",
       "          [ 1.6024e+00,  8.1917e-01,  1.9787e+00,  9.9636e-01],\n",
       "          [ 1.9608e+00,  2.3043e+00,  1.6119e+00,  1.6168e+00],\n",
       "          [ 9.8164e-01,  5.8107e-01,  1.4139e+00,  8.2897e-01],\n",
       "          [ 1.5541e+00,  7.0550e-01,  1.5312e+00,  1.1350e+00],\n",
       "          [ 8.8179e-01,  6.6980e-01,  1.3340e+00,  7.9716e-01],\n",
       "          [ 1.7821e+00,  6.2471e-01,  1.8912e+00,  1.1731e+00],\n",
       "          [ 2.0517e+00,  4.1633e-01,  2.3769e+00,  8.4690e-01],\n",
       "          [ 1.5634e+00,  1.8665e-01,  1.9274e+00,  7.3317e-01],\n",
       "          [ 3.8040e+00,  1.9006e-01,  3.2155e+00,  2.8346e-01],\n",
       "          [ 1.2377e+00,  8.0907e-01,  1.3634e+00,  1.7621e+00],\n",
       "          [ 1.1173e+00,  1.1146e+00,  1.3053e+00,  1.9727e+00],\n",
       "          [ 1.5213e+00,  1.7864e+00,  1.6304e+00,  1.6840e+00],\n",
       "          [ 1.9139e+00,  9.4281e-01,  1.9566e+00,  1.5581e+00],\n",
       "          [ 1.6667e+00,  1.1353e+00,  1.9239e+00,  1.4962e+00],\n",
       "          [ 2.9144e+00,  3.1225e+00,  2.3833e+00,  2.2274e+00]], device='cuda:0',\n",
       "         grad_fn=<IndexBackward>)])}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d9b6de",
   "metadata": {},
   "source": [
    "* train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd3416b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_to_eval.train()\n",
    "( _, proposals_rpn_unsup_k, proposals_roih_unsup_k, _,) = model_to_eval.modelStudent(test_data, branch=\"unsup_data_weak\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c50c0c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detectron2",
   "language": "python",
   "name": "detectron2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
