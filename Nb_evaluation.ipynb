{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfb7a745",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/superorange5/.local/lib/python3.8/site-packages/torchvision/transforms/transforms.py:803: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# to register\n",
    "from pt.modeling.meta_arch.rcnn import GuassianGeneralizedRCNN\n",
    "from pt.modeling.proposal_generator.rpn import GuassianRPN\n",
    "from pt.modeling.roi_heads.roi_heads import GuassianROIHead\n",
    "import pt.data.datasets.builtin\n",
    "from pt.modeling.backbone.vgg import build_vgg_backbone\n",
    "from pt.modeling.anchor_generator import DifferentiableAnchorGenerator\n",
    "\n",
    "\n",
    "from pt.modeling.meta_arch.ts_ensemble import EnsembleTSModel\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e55bf8",
   "metadata": {},
   "source": [
    "## load config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00b600fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.config import get_cfg\n",
    "from pt import add_config\n",
    "\n",
    "def setup(config_file):\n",
    "    \"\"\"\n",
    "    Create configs and perform basic setups.\n",
    "    \"\"\"\n",
    "    cfg = get_cfg()\n",
    "    add_config(cfg)\n",
    "    cfg.merge_from_file(config_file)\n",
    "    #cfg.merge_from_list(args.opts)\n",
    "    \n",
    "    #default_setup(cfg, args)\n",
    "#     cfg.SOLVER.IMG_PER_BATCH_LABEL = 64\n",
    "#     cfg.SOLVER.IMG_PER_BATCH_UNLABEL = 64\n",
    "\n",
    "    cfg.freeze()\n",
    "    return cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7ffd3a",
   "metadata": {},
   "source": [
    "## load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4218b965",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.modeling import build_model\n",
    "from pt.engine.trainer import PTrainer\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_TSmodel(cfg_path, model_path):\n",
    "    cfg = setup(cfg_path)\n",
    "    #cfg.defrost()\n",
    "    #cfg.MODEL.WEIGHTS = model_path\n",
    "    \n",
    "    Trainer =PTrainer\n",
    "    model = Trainer.build_model(cfg)\n",
    "    model_teacher = Trainer.build_model(cfg)\n",
    "    ensem_ts_model = EnsembleTSModel(model_teacher, model)    \n",
    "    \n",
    "    \n",
    "    DetectionCheckpointer(ensem_ts_model).resume_or_load(model_path, resume=False)\n",
    "    \n",
    "    return ensem_ts_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "544642ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "model_folder = 'keep_experiments'\n",
    "\n",
    "def get_model(dataset_name,model_num):\n",
    "    if model_num =='final':\n",
    "        model_name ='model_final.pth'\n",
    "    else:\n",
    "        model_name = 'model_{0:07d}.pth'.format(model_num)\n",
    "    model_path = os.path.join(model_folder,dataset_name,model_name)\n",
    "    cfg_path = os.path.join(model_folder,dataset_name,'cfg.yaml')\n",
    "    print(cfg_path)\n",
    "    print(model_path)\n",
    "    return load_TSmodel(cfg_path, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c470d34c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keep_experiments/s2c/cfg.yaml\n",
      "keep_experiments/s2c/model_0015999.pth\n",
      "-------- pretrained model loaded ---------\n",
      "-------- pretrained model loaded ---------\n",
      "keep_experiments/k2c/cfg.yaml\n",
      "keep_experiments/k2c/model_0019999.pth\n",
      "-------- pretrained model loaded ---------\n",
      "-------- pretrained model loaded ---------\n",
      "keep_experiments/f2c/cfg.yaml\n",
      "keep_experiments/f2c/model_final.pth\n",
      "-------- pretrained model loaded ---------\n",
      "-------- pretrained model loaded ---------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#---------skf2c-------\n",
    "model_s2c = get_model('s2c', 15999)\n",
    "model_k2c = get_model('k2c', 19999)\n",
    "model_f2c = get_model('f2c', 'final') #8class\n",
    "model_list_skf2c=[model_s2c,model_k2c,model_f2c]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3eb12ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keep_experiments/c2b/cfg.yaml\n",
      "keep_experiments/c2b/model_0011999.pth\n",
      "-------- pretrained model loaded ---------\n",
      "-------- pretrained model loaded ---------\n",
      "keep_experiments/k2b/cfg.yaml\n",
      "keep_experiments/k2b/model_final.pth\n",
      "-------- pretrained model loaded ---------\n",
      "-------- pretrained model loaded ---------\n"
     ]
    }
   ],
   "source": [
    "#--------ck2bdd-------\n",
    "model_c2b = get_model('c2b', 11999)\n",
    "model_k2b = get_model('k2b', 'final')\n",
    "model_list_ck2b=[model_c2b,model_k2b]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2793f096",
   "metadata": {},
   "source": [
    "## evaluation (defaults.test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "360a4318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4.9567e-03,  4.1854e-02, -8.4723e-01, -5.3333e-01, -1.7204e+00,\n",
       "        -1.9618e+00, -1.1261e+00, -1.2538e+00,  7.7744e-03,  2.2535e-02,\n",
       "        -2.2750e-01, -4.8190e-01, -7.0024e-01, -8.2286e-01, -5.7922e-01,\n",
       "        -6.0722e-01, -3.5713e-02,  6.8824e-02, -2.9323e-01, -1.2816e+00,\n",
       "        -9.5808e-01, -1.4632e+00, -6.4602e-01, -8.0602e-01, -1.1137e-03,\n",
       "         4.0937e-03, -1.2114e-01, -3.2870e-02, -2.6557e-01, -2.5672e-01,\n",
       "        -2.0734e-01, -1.9663e-01,  4.5403e-03, -7.9842e-03, -4.0569e-03,\n",
       "        -1.0426e-01, -3.1593e-01, -3.0426e-01, -2.6025e-01, -2.3013e-01,\n",
       "        -7.1750e-03,  1.7197e-03, -2.0883e-02, -4.9887e-02, -1.4983e-01,\n",
       "        -1.3809e-01, -1.3263e-01, -1.1133e-01,  3.7207e-03,  9.6099e-04,\n",
       "        -4.0151e-02, -2.8066e-02, -9.2451e-02, -9.5428e-02, -8.6735e-02,\n",
       "        -7.9944e-02,  5.4622e-03,  4.5548e-03, -4.3455e-02, -6.1940e-02,\n",
       "        -1.1308e-01, -1.0045e-01, -1.0183e-01, -8.1233e-02,  2.0255e-03,\n",
       "         4.3722e-03, -2.2436e-02, -2.0772e-02, -5.6462e-02, -5.5159e-02,\n",
       "        -5.0835e-02, -4.9274e-02], device='cuda:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_c2b.modelStudent.state_dict()['proposal_generator.rpn_head.anchor_deltas.bias']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f93a4e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#results = OrderedDict()\n",
    "from detectron2.data import build_detection_test_loader\n",
    "from detectron2.evaluation import PascalVOCDetectionEvaluator\n",
    "from detectron2.evaluation import inference_on_dataset\n",
    "\n",
    "cfg = setup(\"keep_experiments/c2b/cfg.yaml\")\n",
    "\n",
    "dataset_name = 'VOC2007_bddvalsmall'\n",
    "test_data_loader = build_detection_test_loader(cfg, dataset_name)\n",
    "evaluator = PascalVOCDetectionEvaluator(dataset_name)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de265b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader_iter = iter(test_data_loader)\n",
    "data = data_loader_iter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e256337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'file_name': 'data/VOC2007_bddval/JPEGImages/b1c66a42-6f7d68ca.jpg',\n",
       "  'image_id': 'b1c66a42-6f7d68ca',\n",
       "  'height': 720,\n",
       "  'width': 1280,\n",
       "  'image': tensor([[[254, 255, 255,  ...,  57,  54,  51],\n",
       "           [243, 250, 253,  ...,  56,  53,  50],\n",
       "           [206, 231, 243,  ...,  54,  51,  48],\n",
       "           ...,\n",
       "           [ 49,  49,  49,  ...,  28,  28,  28],\n",
       "           [ 47,  47,  47,  ...,  26,  26,  26],\n",
       "           [ 47,  47,  47,  ...,  25,  25,  25]],\n",
       "  \n",
       "          [[254, 255, 254,  ...,  89,  86,  83],\n",
       "           [241, 249, 251,  ...,  88,  85,  82],\n",
       "           [202, 227, 239,  ...,  86,  83,  80],\n",
       "           ...,\n",
       "           [ 58,  58,  58,  ...,  23,  23,  23],\n",
       "           [ 56,  56,  56,  ...,  21,  21,  21],\n",
       "           [ 56,  56,  56,  ...,  20,  20,  20]],\n",
       "  \n",
       "          [[222, 219, 216,  ..., 124, 121, 118],\n",
       "           [207, 215, 217,  ..., 123, 120, 117],\n",
       "           [174, 199, 211,  ..., 121, 118, 115],\n",
       "           ...,\n",
       "           [ 61,  61,  61,  ...,  20,  20,  20],\n",
       "           [ 59,  59,  59,  ...,  18,  18,  18],\n",
       "           [ 59,  59,  59,  ...,  17,  17,  17]]], dtype=torch.uint8)}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7776dd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_c2b.eval()\n",
    "results_i = inference_on_dataset(model_c2b.modelStudent, test_data_loader, evaluator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0f13ae05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('bbox',\n",
       "              {'AP': 34.43792240729627,\n",
       "               'AP50': 55.33559113300493,\n",
       "               'AP75': 42.69925476822028})])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "290e52a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_c2b.modelStudent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "666dac0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    output_result=[]\n",
    "    for model in model_list_ck2b:\n",
    "        modelStudent= model.modelStudent\n",
    "        modelStudent.eval()\n",
    "        output=modelStudent(data)\n",
    "        output_result.append(output)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f75776c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9782, 0.9770, 0.9530, 0.9435, 0.9127, 0.9055, 0.9023, 0.9006, 0.8991,\n",
       "        0.8486, 0.7825, 0.7520, 0.3332, 0.2876, 0.2741, 0.2580, 0.2209, 0.2179,\n",
       "        0.1990, 0.1814, 0.1572, 0.1552, 0.1415, 0.1287, 0.0757, 0.0703, 0.0678,\n",
       "        0.0633, 0.0492, 0.0355, 0.0342, 0.0307, 0.0280, 0.0252, 0.0211, 0.0204,\n",
       "        0.0202, 0.0162, 0.0151, 0.0113, 0.0109, 0.0101, 0.0090, 0.0088, 0.0078,\n",
       "        0.0048, 0.0043, 0.0022, 0.0012], device='cuda:0')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_result[1][0]['instances'].scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1efa0593",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.reset()\n",
    "evaluator.process(data, output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4f489a3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {0: ['b1c66a42-6f7d68ca 0.971 933.1 339.5 1221.0 481.7',\n",
       "              'b1c66a42-6f7d68ca 0.971 796.0 363.4 905.5 430.0',\n",
       "              'b1c66a42-6f7d68ca 0.961 751.1 363.6 820.0 413.1',\n",
       "              'b1c66a42-6f7d68ca 0.946 39.8 351.0 127.8 400.2',\n",
       "              'b1c66a42-6f7d68ca 0.931 882.3 378.1 966.8 448.7',\n",
       "              'b1c66a42-6f7d68ca 0.899 247.1 350.0 349.4 397.7',\n",
       "              'b1c66a42-6f7d68ca 0.896 599.8 355.0 635.8 385.3',\n",
       "              'b1c66a42-6f7d68ca 0.877 1.0 341.4 58.4 403.1',\n",
       "              'b1c66a42-6f7d68ca 0.875 733.7 367.5 771.7 404.4',\n",
       "              'b1c66a42-6f7d68ca 0.756 684.1 360.5 718.3 391.1',\n",
       "              'b1c66a42-6f7d68ca 0.753 1.0 335.7 10.8 391.8',\n",
       "              'b1c66a42-6f7d68ca 0.628 204.9 344.2 258.1 386.0',\n",
       "              'b1c66a42-6f7d68ca 0.594 215.8 359.8 300.0 455.8',\n",
       "              'b1c66a42-6f7d68ca 0.539 709.3 365.5 743.6 398.0',\n",
       "              'b1c66a42-6f7d68ca 0.457 692.2 362.0 737.2 395.2',\n",
       "              'b1c66a42-6f7d68ca 0.418 1204.3 418.6 1279.2 524.1',\n",
       "              'b1c66a42-6f7d68ca 0.257 13.6 346.9 101.7 403.0',\n",
       "              'b1c66a42-6f7d68ca 0.200 587.3 351.0 612.7 376.9',\n",
       "              'b1c66a42-6f7d68ca 0.185 593.7 353.9 622.5 380.1',\n",
       "              'b1c66a42-6f7d68ca 0.181 962.9 256.1 1032.8 309.5',\n",
       "              'b1c66a42-6f7d68ca 0.135 568.2 336.4 607.9 373.0',\n",
       "              'b1c66a42-6f7d68ca 0.112 1.3 346.4 23.2 405.4',\n",
       "              'b1c66a42-6f7d68ca 0.076 230.0 350.6 340.0 426.8',\n",
       "              'b1c66a42-6f7d68ca 0.039 403.3 357.8 438.2 376.7',\n",
       "              'b1c66a42-6f7d68ca 0.033 368.8 354.4 408.5 377.2',\n",
       "              'b1c66a42-6f7d68ca 0.031 672.0 362.1 699.9 387.5',\n",
       "              'b1c66a42-6f7d68ca 0.021 708.3 355.7 757.2 394.3',\n",
       "              'b1c66a42-6f7d68ca 0.018 648.2 363.8 678.3 386.2',\n",
       "              'b1c66a42-6f7d68ca 0.017 363.7 351.7 429.2 379.9',\n",
       "              'b1c66a42-6f7d68ca 0.016 333.5 356.9 374.2 383.0',\n",
       "              'b1c66a42-6f7d68ca 0.014 447.8 357.9 479.6 374.0',\n",
       "              'b1c66a42-6f7d68ca 0.013 233.1 365.1 297.7 417.9',\n",
       "              'b1c66a42-6f7d68ca 0.012 204.1 343.2 308.9 397.0',\n",
       "              'b1c66a42-6f7d68ca 0.011 413.4 359.5 453.1 377.7',\n",
       "              'b1c66a42-6f7d68ca 0.010 353.6 350.6 396.0 374.7',\n",
       "              'b1c66a42-6f7d68ca 0.009 158.2 328.5 238.2 376.3']})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator._predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0a070470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(720, 1280)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0]['instances'].image_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a43c9501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9708, 0.9707, 0.9612, 0.9462, 0.9312, 0.8988, 0.8963, 0.8774, 0.8749,\n",
       "        0.7561, 0.7531, 0.6275, 0.5939, 0.5390, 0.4565, 0.4178, 0.2566, 0.1998,\n",
       "        0.1848, 0.1812, 0.1348, 0.1121, 0.0759, 0.0390, 0.0330, 0.0310, 0.0206,\n",
       "        0.0180, 0.0171, 0.0161, 0.0135, 0.0127, 0.0123, 0.0106, 0.0099, 0.0094],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0]['instances'].pred_boxes\n",
    "output[0]['instances'].scores_logists\n",
    "output[0]['instances'].boxes_sigma\n",
    "output[0]['instances'].scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "405b4c28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Instances.get_fields of Instances(num_instances=36, image_height=720, image_width=1280, fields=[pred_boxes: Boxes(tensor([[9.3210e+02, 3.3852e+02, 1.2210e+03, 4.8170e+02],\n",
       "        [7.9497e+02, 3.6244e+02, 9.0552e+02, 4.3002e+02],\n",
       "        [7.5011e+02, 3.6257e+02, 8.2003e+02, 4.1306e+02],\n",
       "        [3.8800e+01, 3.4999e+02, 1.2780e+02, 4.0018e+02],\n",
       "        [8.8130e+02, 3.7710e+02, 9.6676e+02, 4.4869e+02],\n",
       "        [2.4614e+02, 3.4897e+02, 3.4941e+02, 3.9769e+02],\n",
       "        [5.9876e+02, 3.5402e+02, 6.3575e+02, 3.8532e+02],\n",
       "        [0.0000e+00, 3.4040e+02, 5.8351e+01, 4.0309e+02],\n",
       "        [7.3273e+02, 3.6651e+02, 7.7169e+02, 4.0439e+02],\n",
       "        [6.8310e+02, 3.5948e+02, 7.1826e+02, 3.9106e+02],\n",
       "        [0.0000e+00, 3.3469e+02, 1.0768e+01, 3.9184e+02],\n",
       "        [2.0393e+02, 3.4324e+02, 2.5814e+02, 3.8604e+02],\n",
       "        [2.1476e+02, 3.5879e+02, 3.0001e+02, 4.5576e+02],\n",
       "        [7.0833e+02, 3.6453e+02, 7.4357e+02, 3.9798e+02],\n",
       "        [6.9122e+02, 3.6096e+02, 7.3717e+02, 3.9521e+02],\n",
       "        [1.2033e+03, 4.1763e+02, 1.2792e+03, 5.2414e+02],\n",
       "        [1.2558e+01, 3.4589e+02, 1.0172e+02, 4.0303e+02],\n",
       "        [5.8631e+02, 3.5004e+02, 6.1269e+02, 3.7690e+02],\n",
       "        [5.9269e+02, 3.5286e+02, 6.2253e+02, 3.8014e+02],\n",
       "        [9.6188e+02, 2.5513e+02, 1.0328e+03, 3.0948e+02],\n",
       "        [5.6717e+02, 3.3535e+02, 6.0787e+02, 3.7301e+02],\n",
       "        [2.6411e-01, 3.4545e+02, 2.3222e+01, 4.0542e+02],\n",
       "        [2.2899e+02, 3.4963e+02, 3.3996e+02, 4.2685e+02],\n",
       "        [4.0234e+02, 3.5680e+02, 4.3816e+02, 3.7669e+02],\n",
       "        [3.6780e+02, 3.5338e+02, 4.0846e+02, 3.7721e+02],\n",
       "        [6.7104e+02, 3.6107e+02, 6.9990e+02, 3.8752e+02],\n",
       "        [7.0729e+02, 3.5469e+02, 7.5724e+02, 3.9433e+02],\n",
       "        [6.4716e+02, 3.6279e+02, 6.7828e+02, 3.8616e+02],\n",
       "        [3.6273e+02, 3.5067e+02, 4.2916e+02, 3.7986e+02],\n",
       "        [3.3248e+02, 3.5591e+02, 3.7417e+02, 3.8297e+02],\n",
       "        [4.4679e+02, 3.5686e+02, 4.7964e+02, 3.7400e+02],\n",
       "        [2.3211e+02, 3.6414e+02, 2.9770e+02, 4.1787e+02],\n",
       "        [2.0311e+02, 3.4216e+02, 3.0886e+02, 3.9695e+02],\n",
       "        [4.1240e+02, 3.5850e+02, 4.5306e+02, 3.7772e+02],\n",
       "        [3.5265e+02, 3.4964e+02, 3.9602e+02, 3.7467e+02],\n",
       "        [1.5720e+02, 3.2750e+02, 2.3821e+02, 3.7633e+02]], device='cuda:0')), scores: tensor([0.9708, 0.9707, 0.9612, 0.9462, 0.9312, 0.8988, 0.8963, 0.8774, 0.8749,\n",
       "        0.7561, 0.7531, 0.6275, 0.5939, 0.5390, 0.4565, 0.4178, 0.2566, 0.1998,\n",
       "        0.1848, 0.1812, 0.1348, 0.1121, 0.0759, 0.0390, 0.0330, 0.0310, 0.0206,\n",
       "        0.0180, 0.0171, 0.0161, 0.0135, 0.0127, 0.0123, 0.0106, 0.0099, 0.0094],\n",
       "       device='cuda:0'), pred_classes: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0'), scores_logists: tensor([[ 3.3746, -3.4222],\n",
       "        [ 3.0637, -3.1017],\n",
       "        [ 3.7150, -3.7093],\n",
       "        [ 3.2326, -3.2229],\n",
       "        [ 2.6753, -2.6198],\n",
       "        [ 2.1805, -2.2141],\n",
       "        [ 2.9142, -2.8905],\n",
       "        [ 2.7713, -2.7547],\n",
       "        [ 2.6244, -2.6060],\n",
       "        [ 1.7956, -1.8262],\n",
       "        [ 1.2354, -1.2762],\n",
       "        [ 1.0564, -1.0052],\n",
       "        [ 0.5821, -0.5865],\n",
       "        [ 2.3656, -2.3056],\n",
       "        [ 1.9363, -1.8746],\n",
       "        [ 0.0897, -0.0704],\n",
       "        [ 0.1624, -0.1088],\n",
       "        [ 0.3955, -0.3212],\n",
       "        [-0.0378,  0.0782],\n",
       "        [-0.4594,  0.4989],\n",
       "        [ 0.0195,  0.0350],\n",
       "        [-0.5129,  0.6021],\n",
       "        [-0.6291,  0.5911],\n",
       "        [-0.6431,  0.6644],\n",
       "        [-0.7335,  0.7555],\n",
       "        [-1.1361,  1.1194],\n",
       "        [-1.2835,  1.2587],\n",
       "        [-1.4107,  1.3891],\n",
       "        [-1.1443,  1.1682],\n",
       "        [-1.3804,  1.4071],\n",
       "        [-1.2687,  1.2785],\n",
       "        [-1.1065,  1.0902],\n",
       "        [-1.2292,  1.2823],\n",
       "        [-1.4174,  1.4435],\n",
       "        [-1.2412,  1.2587],\n",
       "        [-1.2616,  1.3054]], device='cuda:0'), boxes_sigma: tensor([[-3.4894e+00, -3.9871e+00, -3.1702e+00, -3.6849e+00],\n",
       "        [-3.6285e+00, -3.7810e+00, -3.3161e+00, -3.6317e+00],\n",
       "        [-3.2193e+00, -3.3684e+00, -2.9709e+00, -3.3978e+00],\n",
       "        [-2.8282e+00, -3.2153e+00, -2.5468e+00, -3.1238e+00],\n",
       "        [-2.9457e+00, -2.7821e+00, -2.3568e+00, -2.7212e+00],\n",
       "        [-2.2454e+00, -2.4638e+00, -2.3135e+00, -2.2387e+00],\n",
       "        [-2.2998e+00, -2.2267e+00, -2.0085e+00, -2.2291e+00],\n",
       "        [-1.8328e+00, -2.2246e+00, -1.6705e+00, -2.4066e+00],\n",
       "        [-1.6395e+00, -2.2094e+00, -1.8167e+00, -2.4366e+00],\n",
       "        [-6.3844e-01, -1.7724e+00, -9.5738e-01, -1.9336e+00],\n",
       "        [-1.0417e+00, -2.0666e+00, -1.1329e+00, -1.9339e+00],\n",
       "        [-1.2190e+00, -8.2443e-01, -8.5451e-01, -6.6751e-01],\n",
       "        [-2.6278e+00, -8.5548e-01, -1.8027e+00, -4.9464e-01],\n",
       "        [ 2.1113e+00, -1.0854e+00,  2.1824e-01, -1.9466e+00],\n",
       "        [ 2.8271e+00, -7.2808e-01,  8.0095e-01, -1.5608e+00],\n",
       "        [-1.6114e+00, -1.4486e+00, -8.4586e-01, -1.1116e+00],\n",
       "        [ 3.1729e+00, -1.0267e+00,  1.2308e+00, -1.4266e+00],\n",
       "        [ 3.1314e+00,  8.1953e-01,  1.2376e+00, -4.7690e-01],\n",
       "        [ 2.4866e+00,  1.3186e-01,  7.3442e-01, -8.5484e-01],\n",
       "        [-1.1308e+00, -7.3917e-01, -7.5899e-01, -3.8568e-03],\n",
       "        [ 1.8357e+00,  9.9503e-01,  1.2337e+00,  1.8653e-01],\n",
       "        [ 1.5066e+00, -7.3187e-01,  9.9331e-01, -7.9625e-01],\n",
       "        [ 5.4917e-01,  1.0312e+00,  1.8521e-03,  1.3660e+00],\n",
       "        [ 3.4687e+00,  8.6966e-01,  2.7240e+00,  6.3711e-01],\n",
       "        [ 3.8583e+00,  9.9451e-01,  2.8327e+00,  5.2888e-01],\n",
       "        [ 2.8155e+00,  1.9625e-02,  1.6531e+00, -3.8845e-01],\n",
       "        [ 2.0822e+00,  1.3365e+00,  4.5690e-01,  3.0951e-01],\n",
       "        [ 1.7686e+00,  4.5190e-01,  1.1205e+00,  1.0960e-01],\n",
       "        [ 3.9331e+00,  6.2073e-01,  2.8754e+00,  6.7833e-01],\n",
       "        [ 1.8394e+00,  6.3322e-01,  1.3783e+00,  3.1600e-01],\n",
       "        [ 2.7966e+00,  9.2719e-01,  2.4099e+00,  7.4733e-01],\n",
       "        [ 1.8358e+00,  3.3710e+00,  9.0747e-01,  2.9145e+00],\n",
       "        [ 2.7825e+00,  1.2857e+00,  1.4918e+00,  1.4196e+00],\n",
       "        [ 3.2516e+00,  7.1087e-01,  2.5742e+00,  6.2980e-01],\n",
       "        [ 3.9875e+00,  1.6074e+00,  2.6586e+00,  9.8108e-01],\n",
       "        [ 3.2888e+00,  1.4530e+00,  2.3090e+00,  1.3315e+00]], device='cuda:0')])>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0]['instances'].get_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d8c25d81",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'method' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_24712/494066295.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_c2b\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodelStudent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/ProbabilisticTeacher/pt/modeling/meta_arch/rcnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, batched_inputs, branch, danchor, norm)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatched_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"instances\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatched_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_image_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatched_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'method' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "for idx, inputs in enumerate(test_data_loader):\n",
    "    output = model_c2b.modelStudent(input)\n",
    "    print(output)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0cd296ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(next(g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4d1f78c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_24712/4279426661.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mget_all_inputs_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_c2b\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodelTeacher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m       \u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0meval_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_24712/4279426661.py\u001b[0m in \u001b[0;36mget_all_inputs_outputs\u001b[0;34m(data_loader, model)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_all_inputs_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/ProbabilisticTeacher/pt/modeling/meta_arch/rcnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, batched_inputs, branch, danchor, norm)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbranch\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"supervised\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;31m# Region proposal network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             proposals_rpn, proposal_losses = self.proposal_generator(\n\u001b[0m\u001b[1;32m     51\u001b[0m                 \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_instances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             )\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/ProbabilisticTeacher/pt/modeling/proposal_generator/rpn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, images, features, gt_instances, compute_loss, branch, danchor)\u001b[0m\n\u001b[1;32m    135\u001b[0m             )\n\u001b[1;32m    136\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0mgt_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_boxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_and_sample_anchors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manchors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_instances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m             losses = self.losses(\n\u001b[1;32m    139\u001b[0m                 \u001b[0manchors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_objectness_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_anchor_deltas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_boxes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/ProbabilisticTeacher/pt/modeling/proposal_generator/rpn.py\u001b[0m in \u001b[0;36mlabel_and_sample_anchors\u001b[0;34m(self, anchors, gt_instances, use_ignore, use_soft_label)\u001b[0m\n\u001b[1;32m    382\u001b[0m         \"\"\"\n\u001b[1;32m    383\u001b[0m         \u001b[0manchors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBoxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manchors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m         \u001b[0mhas_pseudo_boxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgt_instances\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pseudo_boxes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0mimage_sizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_size\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgt_instances\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhas_pseudo_boxes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "def get_all_inputs_outputs(data_loader,model):\n",
    "    for data in data_loader:\n",
    "        yield data, model(data)\n",
    "\n",
    "\n",
    "evaluator.reset()\n",
    "for inputs, outputs in get_all_inputs_outputs(test_data_loader,model_c2b.modelTeacher):\n",
    "      evaluator.process(inputs, outputs)\n",
    "eval_results = evaluator.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8798d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, inputs in enumerate(test_data_loader):\n",
    "\n",
    "    outputs = model_teacher(inputs)\n",
    "    evaluator.process(inputs, outputs)\n",
    "results = evaluator.evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detectron2",
   "language": "python",
   "name": "detectron2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
