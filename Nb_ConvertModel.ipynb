{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86a8e5d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE! Installing ujson may make loading annotations faster.\n"
     ]
    }
   ],
   "source": [
    "from detectron2.modeling import build_model\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.evaluation import PascalVOCDetectionEvaluator\n",
    "from detectron2.config import get_cfg\n",
    "import torch\n",
    "from pt import add_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1270d475",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FRCNNTrainer(DefaultTrainer):\n",
    "    \"\"\"\n",
    "    We use the \"DefaultTrainer\" which contains pre-defined default logic for\n",
    "    standard training workflow. They may not work for you, especially if you\n",
    "    are working on a new research project. In that case you can write your\n",
    "    own training loop. You can use \"tools/plain_train_net.py\" as an example.\n",
    "    \"\"\"\n",
    "\n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "        if output_folder is None:\n",
    "            output_folder = os.path.join(cfg.OUTPUT_DIR, \"inference\")\n",
    "\n",
    "        if cfg.TEST.EVALUATOR == \"COCOeval\":\n",
    "            return COCOEvaluator(dataset_name, cfg, True, output_folder)\n",
    "        if cfg.TEST.EVALUATOR == \"VOCeval\":\n",
    "            return PascalVOCDetectionEvaluator(dataset_name)\n",
    "        else:\n",
    "            raise ValueError(\"Unknown test evaluator.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c066afa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def setup(config_file):\n",
    "    \"\"\"\n",
    "    Create configs and perform basic setups.\n",
    "    \"\"\"\n",
    "    cfg = get_cfg()\n",
    "    add_config(cfg)\n",
    "    cfg.merge_from_file(config_file)\n",
    "    #cfg.merge_from_list(args.opts)\n",
    "    \n",
    "    #default_setup(cfg, args)\n",
    "#     cfg.SOLVER.IMG_PER_BATCH_LABEL = 64\n",
    "#     cfg.SOLVER.IMG_PER_BATCH_UNLABEL = 64\n",
    "\n",
    "    cfg.freeze()\n",
    "    return cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d89b9aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_path = \"configs/FedAvg/bddeval.yaml\"\n",
    "model_path= \"models/multi_ck_FedAvg/faster_rcnn_multi_ck_AVG_2.pth\"\n",
    "cfg = setup(cfg_path)\n",
    "#cfg.defrost()\n",
    "    #cfg.MODEL.WEIGHTS = model_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263daf56",
   "metadata": {},
   "source": [
    "### try load only to see the weight key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b671007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modelTeacher.backbone.vgg_block1.0.conv1.weight\n",
      "modelTeacher.backbone.vgg_block1.0.conv1.bias\n",
      "modelTeacher.backbone.vgg_block1.0.conv2.weight\n",
      "modelTeacher.backbone.vgg_block1.0.conv2.bias\n",
      "modelTeacher.backbone.vgg_block2.0.conv1.weight\n",
      "modelTeacher.backbone.vgg_block2.0.conv1.bias\n",
      "modelTeacher.backbone.vgg_block2.0.conv2.weight\n",
      "modelTeacher.backbone.vgg_block2.0.conv2.bias\n",
      "modelTeacher.backbone.vgg_block3.0.conv1.weight\n",
      "modelTeacher.backbone.vgg_block3.0.conv1.bias\n",
      "modelTeacher.backbone.vgg_block3.0.conv2.weight\n",
      "modelTeacher.backbone.vgg_block3.0.conv2.bias\n",
      "modelTeacher.backbone.vgg_block3.0.conv3.weight\n",
      "modelTeacher.backbone.vgg_block3.0.conv3.bias\n",
      "modelTeacher.backbone.vgg_block4.0.conv1.weight\n",
      "modelTeacher.backbone.vgg_block4.0.conv1.bias\n",
      "modelTeacher.backbone.vgg_block4.0.conv2.weight\n",
      "modelTeacher.backbone.vgg_block4.0.conv2.bias\n",
      "modelTeacher.backbone.vgg_block4.0.conv3.weight\n",
      "modelTeacher.backbone.vgg_block4.0.conv3.bias\n",
      "modelTeacher.backbone.vgg_block5.0.conv1.weight\n",
      "modelTeacher.backbone.vgg_block5.0.conv1.bias\n",
      "modelTeacher.backbone.vgg_block5.0.conv2.weight\n",
      "modelTeacher.backbone.vgg_block5.0.conv2.bias\n",
      "modelTeacher.backbone.vgg_block5.0.conv3.weight\n",
      "modelTeacher.backbone.vgg_block5.0.conv3.bias\n",
      "modelTeacher.proposal_generator.rpn_head.conv.weight\n",
      "modelTeacher.proposal_generator.rpn_head.conv.bias\n",
      "modelTeacher.proposal_generator.rpn_head.objectness_logits.weight\n",
      "modelTeacher.proposal_generator.rpn_head.objectness_logits.bias\n",
      "modelTeacher.proposal_generator.rpn_head.anchor_deltas.weight\n",
      "modelTeacher.proposal_generator.rpn_head.anchor_deltas.bias\n",
      "modelTeacher.roi_heads.box_head.fc1.weight\n",
      "modelTeacher.roi_heads.box_head.fc1.bias\n",
      "modelTeacher.roi_heads.box_head.fc2.weight\n",
      "modelTeacher.roi_heads.box_head.fc2.bias\n",
      "modelTeacher.roi_heads.box_predictor.cls_score.weight\n",
      "modelTeacher.roi_heads.box_predictor.cls_score.bias\n",
      "modelTeacher.roi_heads.box_predictor.bbox_pred.weight\n",
      "modelTeacher.roi_heads.box_predictor.bbox_pred.bias\n",
      "modelStudent.backbone.vgg_block1.0.conv1.weight\n",
      "modelStudent.backbone.vgg_block1.0.conv1.bias\n",
      "modelStudent.backbone.vgg_block1.0.conv2.weight\n",
      "modelStudent.backbone.vgg_block1.0.conv2.bias\n",
      "modelStudent.backbone.vgg_block2.0.conv1.weight\n",
      "modelStudent.backbone.vgg_block2.0.conv1.bias\n",
      "modelStudent.backbone.vgg_block2.0.conv2.weight\n",
      "modelStudent.backbone.vgg_block2.0.conv2.bias\n",
      "modelStudent.backbone.vgg_block3.0.conv1.weight\n",
      "modelStudent.backbone.vgg_block3.0.conv1.bias\n",
      "modelStudent.backbone.vgg_block3.0.conv2.weight\n",
      "modelStudent.backbone.vgg_block3.0.conv2.bias\n",
      "modelStudent.backbone.vgg_block3.0.conv3.weight\n",
      "modelStudent.backbone.vgg_block3.0.conv3.bias\n",
      "modelStudent.backbone.vgg_block4.0.conv1.weight\n",
      "modelStudent.backbone.vgg_block4.0.conv1.bias\n",
      "modelStudent.backbone.vgg_block4.0.conv2.weight\n",
      "modelStudent.backbone.vgg_block4.0.conv2.bias\n",
      "modelStudent.backbone.vgg_block4.0.conv3.weight\n",
      "modelStudent.backbone.vgg_block4.0.conv3.bias\n",
      "modelStudent.backbone.vgg_block5.0.conv1.weight\n",
      "modelStudent.backbone.vgg_block5.0.conv1.bias\n",
      "modelStudent.backbone.vgg_block5.0.conv2.weight\n",
      "modelStudent.backbone.vgg_block5.0.conv2.bias\n",
      "modelStudent.backbone.vgg_block5.0.conv3.weight\n",
      "modelStudent.backbone.vgg_block5.0.conv3.bias\n",
      "modelStudent.proposal_generator.rpn_head.conv.weight\n",
      "modelStudent.proposal_generator.rpn_head.conv.bias\n",
      "modelStudent.proposal_generator.rpn_head.objectness_logits.weight\n",
      "modelStudent.proposal_generator.rpn_head.objectness_logits.bias\n",
      "modelStudent.proposal_generator.rpn_head.anchor_deltas.weight\n",
      "modelStudent.proposal_generator.rpn_head.anchor_deltas.bias\n",
      "modelStudent.roi_heads.box_head.fc1.weight\n",
      "modelStudent.roi_heads.box_head.fc1.bias\n",
      "modelStudent.roi_heads.box_head.fc2.weight\n",
      "modelStudent.roi_heads.box_head.fc2.bias\n",
      "modelStudent.roi_heads.box_predictor.cls_score.weight\n",
      "modelStudent.roi_heads.box_predictor.cls_score.bias\n",
      "modelStudent.roi_heads.box_predictor.bbox_pred.weight\n",
      "modelStudent.roi_heads.box_predictor.bbox_pred.bias\n"
     ]
    }
   ],
   "source": [
    "pt_model = torch.load(\"models/avg_ck2b/pt_ck2b_AVG.pth\")\n",
    "for key in pt_model:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcd91f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.0.weight\n",
      "features.0.bias\n",
      "features.2.weight\n",
      "features.2.bias\n",
      "features.5.weight\n",
      "features.5.bias\n",
      "features.7.weight\n",
      "features.7.bias\n",
      "features.10.weight\n",
      "features.10.bias\n",
      "features.12.weight\n",
      "features.12.bias\n",
      "features.14.weight\n",
      "features.14.bias\n",
      "features.17.weight\n",
      "features.17.bias\n",
      "features.19.weight\n",
      "features.19.bias\n",
      "features.21.weight\n",
      "features.21.bias\n",
      "features.24.weight\n",
      "features.24.bias\n",
      "features.26.weight\n",
      "features.26.bias\n",
      "features.28.weight\n",
      "features.28.bias\n",
      "classifier.6.weight\n",
      "classifier.6.bias\n",
      "classifier.0.weight\n",
      "classifier.0.bias\n",
      "classifier.3.weight\n",
      "classifier.3.bias\n"
     ]
    }
   ],
   "source": [
    "pretrain_model = torch.load(\"vgg16_caffe.pth\")\n",
    "for key in pretrain_model:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bdc36c4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 2.4863e-03,  6.1109e-03,  1.0541e-02],\n",
       "          [ 4.4930e-03,  6.5877e-03,  5.9534e-03],\n",
       "          [ 4.8523e-03,  1.4529e-03,  1.0064e-03]],\n",
       "\n",
       "         [[ 1.3604e-02, -3.1343e-02, -3.3258e-02],\n",
       "          [-4.0059e-03, -5.5436e-02, -4.0781e-02],\n",
       "          [-1.1953e-02, -2.4306e-02, -1.0454e-02]],\n",
       "\n",
       "         [[-1.0296e-02, -2.3228e-02,  3.9421e-03],\n",
       "          [-1.5638e-02, -5.5609e-03,  1.3413e-02],\n",
       "          [ 4.9837e-03,  1.6012e-02,  5.5850e-03]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 2.1405e-03,  2.8309e-03,  9.6122e-04],\n",
       "          [ 3.7827e-03,  2.7053e-03,  1.5234e-03],\n",
       "          [-5.6953e-03,  2.3174e-03, -3.7228e-03]],\n",
       "\n",
       "         [[ 1.6126e-02,  4.8720e-02,  2.7729e-02],\n",
       "          [ 3.5497e-03,  5.0776e-02,  3.9638e-02],\n",
       "          [-3.8769e-03,  1.9831e-02,  1.5998e-02]],\n",
       "\n",
       "         [[-3.5147e-03, -2.0347e-02, -1.7734e-02],\n",
       "          [ 2.4222e-03, -2.2734e-02, -1.7978e-02],\n",
       "          [ 1.3569e-02, -3.8954e-03, -4.0953e-03]]],\n",
       "\n",
       "\n",
       "        [[[ 3.2910e-03,  5.4482e-03,  7.4480e-03],\n",
       "          [-3.9808e-03, -3.8431e-03,  8.9432e-04],\n",
       "          [-2.4604e-03, -6.4260e-03, -5.1991e-03]],\n",
       "\n",
       "         [[ 3.8091e-03,  1.4572e-02,  1.5569e-02],\n",
       "          [-2.4177e-02, -2.0081e-02,  4.7858e-03],\n",
       "          [-1.8036e-02, -1.8264e-02, -9.7009e-04]],\n",
       "\n",
       "         [[ 1.1105e-02,  2.0891e-02,  1.4894e-02],\n",
       "          [-5.0001e-03, -1.3886e-02, -1.1802e-02],\n",
       "          [-1.6689e-02, -1.2573e-02, -1.8603e-03]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 2.1735e-03,  5.6354e-03, -2.2798e-03],\n",
       "          [-7.2007e-03, -5.4539e-03, -6.4797e-03],\n",
       "          [-1.7409e-02, -1.6209e-02, -1.8636e-02]],\n",
       "\n",
       "         [[ 8.0474e-05,  1.2414e-02,  1.7065e-02],\n",
       "          [-7.9117e-03,  1.5166e-03,  1.5877e-02],\n",
       "          [-2.4098e-02, -1.1219e-02,  8.1164e-03]],\n",
       "\n",
       "         [[ 1.0832e-02,  1.3821e-03,  1.0299e-02],\n",
       "          [-1.4211e-02, -3.0095e-02, -2.9443e-02],\n",
       "          [-2.0995e-02, -3.5394e-02, -3.7513e-02]]],\n",
       "\n",
       "\n",
       "        [[[-3.1307e-02,  1.5754e-02, -3.3656e-02],\n",
       "          [ 1.7221e-02,  6.6234e-02,  1.0584e-02],\n",
       "          [-9.6275e-03,  1.1482e-02, -3.7567e-02]],\n",
       "\n",
       "         [[-3.5044e-02,  1.1874e-02, -2.8915e-04],\n",
       "          [-1.1093e-02,  3.3918e-02,  1.4479e-02],\n",
       "          [-3.3640e-02,  1.5035e-02,  1.9442e-02]],\n",
       "\n",
       "         [[-1.0556e-02,  1.1154e-02, -1.5925e-02],\n",
       "          [ 4.8171e-03,  3.9598e-02,  4.1915e-03],\n",
       "          [-1.2058e-02,  1.2271e-02, -8.0958e-03]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-4.0928e-02,  1.7261e-02, -4.5433e-02],\n",
       "          [ 2.2457e-02,  8.9447e-02,  1.0068e-02],\n",
       "          [-3.6453e-02,  1.7178e-02, -4.5435e-02]],\n",
       "\n",
       "         [[-3.9527e-02,  3.6491e-02,  2.0111e-02],\n",
       "          [ 6.5057e-03,  8.1859e-02,  3.9229e-02],\n",
       "          [-5.6098e-02,  1.7076e-02, -1.2363e-02]],\n",
       "\n",
       "         [[-2.2383e-02, -2.3567e-02, -3.9065e-02],\n",
       "          [ 3.4053e-02,  3.8525e-02,  1.2827e-02],\n",
       "          [-1.5240e-02, -1.6401e-02, -3.3372e-02]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[ 4.7185e-03,  5.6078e-03,  2.6285e-04],\n",
       "          [ 8.4289e-03,  5.4626e-03,  4.8983e-04],\n",
       "          [ 1.0744e-02,  1.1786e-02,  7.4498e-03]],\n",
       "\n",
       "         [[ 8.5037e-03,  1.2186e-02, -3.6056e-03],\n",
       "          [-1.5268e-02, -2.6579e-02, -5.6272e-03],\n",
       "          [-1.4768e-02, -2.6381e-02, -1.2929e-04]],\n",
       "\n",
       "         [[ 1.1812e-02,  2.3615e-02,  1.3924e-02],\n",
       "          [ 5.5185e-03, -7.2583e-04, -8.1328e-03],\n",
       "          [-1.5913e-02, -1.9032e-02, -6.1827e-03]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-8.3419e-03, -2.7621e-03, -8.1087e-03],\n",
       "          [ 1.2173e-02,  2.4511e-02,  1.5630e-02],\n",
       "          [ 7.0636e-03,  1.2386e-02,  1.3078e-02]],\n",
       "\n",
       "         [[-3.9445e-03,  9.3043e-03,  8.1645e-03],\n",
       "          [ 5.7585e-03,  2.1639e-02,  1.7269e-02],\n",
       "          [-1.2288e-02, -1.6276e-02,  2.8782e-03]],\n",
       "\n",
       "         [[ 1.9216e-02,  3.2418e-02,  2.6521e-02],\n",
       "          [-8.0989e-03, -9.5104e-03, -1.6007e-02],\n",
       "          [-2.8799e-02, -4.7324e-02, -4.8249e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 6.1005e-04,  1.9398e-03, -6.1368e-03],\n",
       "          [-1.0497e-04,  2.6917e-03,  5.2444e-04],\n",
       "          [-2.8459e-03,  8.5163e-04,  4.3181e-05]],\n",
       "\n",
       "         [[ 4.9989e-03,  1.4944e-02,  1.4951e-02],\n",
       "          [ 6.8113e-03,  7.7776e-03, -4.8581e-04],\n",
       "          [ 1.0286e-02,  2.3062e-02,  9.8220e-03]],\n",
       "\n",
       "         [[ 4.1463e-03,  1.0609e-02,  3.2259e-03],\n",
       "          [ 4.6234e-03,  4.4389e-03, -4.4621e-03],\n",
       "          [ 1.3186e-02,  1.4327e-02,  1.7164e-04]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 2.3574e-02,  3.2755e-02,  3.8412e-03],\n",
       "          [ 1.6618e-02,  5.1059e-02,  3.7230e-02],\n",
       "          [-1.5861e-02,  7.5323e-03,  3.2272e-04]],\n",
       "\n",
       "         [[ 8.4203e-03,  5.3481e-03,  4.3715e-03],\n",
       "          [-5.2543e-04,  1.2613e-02,  2.4198e-02],\n",
       "          [-3.0463e-03, -2.7269e-03,  2.0477e-03]],\n",
       "\n",
       "         [[ 4.2197e-03,  2.1941e-02,  1.8889e-02],\n",
       "          [ 6.4051e-03,  8.1807e-03, -5.1692e-03],\n",
       "          [ 1.7409e-02,  1.9767e-02,  3.4187e-03]]],\n",
       "\n",
       "\n",
       "        [[[ 1.0806e-02,  1.4920e-02,  1.3331e-02],\n",
       "          [ 5.7458e-03,  9.3895e-03,  9.3848e-03],\n",
       "          [-1.9098e-03, -2.8267e-03, -3.2230e-04]],\n",
       "\n",
       "         [[ 2.4537e-04,  2.6073e-03,  7.6524e-03],\n",
       "          [-3.0549e-03,  1.4533e-02,  1.2907e-02],\n",
       "          [-3.3699e-03,  4.7121e-03, -1.0776e-03]],\n",
       "\n",
       "         [[ 1.0499e-02,  4.3125e-03,  6.0247e-03],\n",
       "          [ 5.2882e-03,  2.6215e-03,  8.4300e-03],\n",
       "          [ 2.9456e-04, -9.1646e-04,  7.0670e-03]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.8547e-02, -1.7373e-02, -1.6524e-02],\n",
       "          [-2.8523e-02, -3.4355e-02, -3.2173e-02],\n",
       "          [-2.6111e-02, -2.9898e-02, -3.3529e-02]],\n",
       "\n",
       "         [[-6.9804e-04,  6.8055e-03,  8.1304e-03],\n",
       "          [-3.2911e-03,  1.8151e-03,  5.9108e-03],\n",
       "          [-1.0354e-03, -1.8317e-03, -6.4019e-04]],\n",
       "\n",
       "         [[-1.5571e-02, -3.0263e-02, -1.6868e-02],\n",
       "          [-2.3236e-02, -3.7093e-02, -2.0025e-02],\n",
       "          [-1.8697e-02, -2.8749e-02, -1.3151e-02]]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrain_model['features.10.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4a9e130",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4741/2212625458.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mload_avgmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mload_avgmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#load_avgmodel['modelStudent.proposal_generator.rpn_head.anchor_deltas.bias']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_path' is not defined"
     ]
    }
   ],
   "source": [
    "load_avgmodel = torch.load(model_path)\n",
    "for key in load_avgmodel['model']:\n",
    "    print(key)\n",
    "#load_avgmodel['modelStudent.proposal_generator.rpn_head.anchor_deltas.bias']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a8f9e0",
   "metadata": {},
   "source": [
    "## convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "94547dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- pretrained model loaded ---------\n"
     ]
    }
   ],
   "source": [
    "state_dict = torch.load('vgg16_caffe.pth')\n",
    "dict_map_pth = ['features.0.weight', 'features.0.bias', 'features.2.weight', 'features.2.bias',\n",
    "                'features.5.weight', 'features.5.bias', 'features.7.weight', 'features.7.bias',\n",
    "                'features.10.weight', 'features.10.bias', 'features.12.weight', 'features.12.bias',\n",
    "                'features.14.weight', 'features.14.bias', 'features.17.weight', 'features.17.bias',\n",
    "                'features.19.weight', 'features.19.bias', 'features.21.weight', 'features.21.bias',\n",
    "                'features.24.weight', 'features.24.bias', 'features.26.weight', 'features.26.bias',\n",
    "                'features.28.weight', 'features.28.bias',\n",
    "               ]\n",
    "dict_map_model = ['vgg_block1.0.conv1.weight', 'vgg_block1.0.conv1.bias', 'vgg_block1.0.conv2.weight',\n",
    "                  'vgg_block1.0.conv2.bias', 'vgg_block2.0.conv1.weight', 'vgg_block2.0.conv1.bias',\n",
    "                  'vgg_block2.0.conv2.weight', 'vgg_block2.0.conv2.bias', 'vgg_block3.0.conv1.weight',\n",
    "                  'vgg_block3.0.conv1.bias', 'vgg_block3.0.conv2.weight', 'vgg_block3.0.conv2.bias',\n",
    "                  'vgg_block3.0.conv3.weight', 'vgg_block3.0.conv3.bias', 'vgg_block4.0.conv1.weight',\n",
    "                  'vgg_block4.0.conv1.bias', 'vgg_block4.0.conv2.weight', 'vgg_block4.0.conv2.bias',\n",
    "                  'vgg_block4.0.conv3.weight', 'vgg_block4.0.conv3.bias', 'vgg_block5.0.conv1.weight',\n",
    "                  'vgg_block5.0.conv1.bias', 'vgg_block5.0.conv2.weight', 'vgg_block5.0.conv2.bias',\n",
    "                  'vgg_block5.0.conv3.weight', 'vgg_block5.0.conv3.bias']\n",
    "assert len(dict_map_pth) == len(dict_map_model)\n",
    "state_dict_new = {}\n",
    "for i in range(len(dict_map_pth)):\n",
    "    state_dict_new['{}'.format(dict_map_model[i])] = state_dict['{}'.format(dict_map_pth[i])]\n",
    "#torch.nn.Module.load_state_dict({k: v for k, v in state_dict_new.items() if\n",
    "#                      k in torch.nn.Module.state_dict()}, strict=False)\n",
    "print('-------- pretrained model loaded ---------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7e20049b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(state_dict_new, \"tmp.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e6c14296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backbone.vgg_block1.0.conv1.weight\n",
      "backbone.vgg_block1.0.conv1.bias\n",
      "backbone.vgg_block1.0.conv2.weight\n",
      "backbone.vgg_block1.0.conv2.bias\n",
      "backbone.vgg_block2.0.conv1.weight\n",
      "backbone.vgg_block2.0.conv1.bias\n",
      "backbone.vgg_block2.0.conv2.weight\n",
      "backbone.vgg_block2.0.conv2.bias\n",
      "backbone.vgg_block3.0.conv1.weight\n",
      "backbone.vgg_block3.0.conv1.bias\n",
      "backbone.vgg_block3.0.conv2.weight\n",
      "backbone.vgg_block3.0.conv2.bias\n",
      "backbone.vgg_block3.0.conv3.weight\n",
      "backbone.vgg_block3.0.conv3.bias\n",
      "backbone.vgg_block4.0.conv1.weight\n",
      "backbone.vgg_block4.0.conv1.bias\n",
      "backbone.vgg_block4.0.conv2.weight\n",
      "backbone.vgg_block4.0.conv2.bias\n",
      "backbone.vgg_block4.0.conv3.weight\n",
      "backbone.vgg_block4.0.conv3.bias\n",
      "backbone.vgg_block5.0.conv1.weight\n",
      "backbone.vgg_block5.0.conv1.bias\n",
      "backbone.vgg_block5.0.conv2.weight\n",
      "backbone.vgg_block5.0.conv2.bias\n",
      "backbone.vgg_block5.0.conv3.weight\n",
      "backbone.vgg_block5.0.conv3.bias\n",
      "proposal_generator.rpn_head.conv.weight\n",
      "proposal_generator.rpn_head.conv.bias\n",
      "proposal_generator.rpn_head.objectness_logits.weight\n",
      "proposal_generator.rpn_head.objectness_logits.bias\n",
      "proposal_generator.rpn_head.anchor_deltas.weight\n",
      "proposal_generator.rpn_head.anchor_deltas.bias\n",
      "roi_heads.box_head.fc1.weight\n",
      "roi_heads.box_head.fc1.bias\n",
      "roi_heads.box_head.fc2.weight\n",
      "roi_heads.box_head.fc2.bias\n",
      "roi_heads.box_predictor.cls_score.weight\n",
      "roi_heads.box_predictor.cls_score.bias\n",
      "roi_heads.box_predictor.bbox_pred.weight\n",
      "roi_heads.box_predictor.bbox_pred.bias\n"
     ]
    }
   ],
   "source": [
    "load_avgmodel = torch.load(\"tmp.pth\")\n",
    "for key in load_avgmodel:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "70c3603a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_old_frcnn(state_dict,new_path):\n",
    "    dict_map_pth = ['RCNN_base.0.weight', 'RCNN_base.0.bias', 'RCNN_base.2.weight', 'RCNN_base.2.bias',\n",
    "                    'RCNN_base.5.weight', 'RCNN_base.5.bias', 'RCNN_base.7.weight', 'RCNN_base.7.bias',\n",
    "                    'RCNN_base.10.weight', 'RCNN_base.10.bias', 'RCNN_base.12.weight', 'RCNN_base.12.bias',\n",
    "                    'RCNN_base.14.weight', 'RCNN_base.14.bias', 'RCNN_base.17.weight', 'RCNN_base.17.bias',\n",
    "                    'RCNN_base.19.weight', 'RCNN_base.19.bias', 'RCNN_base.21.weight', 'RCNN_base.21.bias',\n",
    "                    'RCNN_base.24.weight', 'RCNN_base.24.bias', 'RCNN_base.26.weight', 'RCNN_base.26.bias',\n",
    "                    'RCNN_base.28.weight', 'RCNN_base.28.bias',\n",
    "                   'RCNN_rpn.RPN_Conv.weight','RCNN_rpn.RPN_Conv.bias',\n",
    "                    'RCNN_rpn.RPN_cls_score.weight','RCNN_rpn.RPN_cls_score.bias',\n",
    "                    'RCNN_rpn.RPN_bbox_pred.weight','RCNN_rpn.RPN_bbox_pred.bias',\n",
    "                   'RCNN_top.0.weight','RCNN_top.0.bias','RCNN_top.3.weight','RCNN_top.3.bias',\n",
    "                    'RCNN_cls_score.weight','RCNN_cls_score.bias',\n",
    "                    'RCNN_bbox_pred.weight','RCNN_bbox_pred.bias']\n",
    "    dict_map_model = ['backbone.vgg_block1.0.conv1.weight', 'backbone.vgg_block1.0.conv1.bias', 'backbone.vgg_block1.0.conv2.weight',\n",
    "                      'backbone.vgg_block1.0.conv2.bias', 'backbone.vgg_block2.0.conv1.weight', 'backbone.vgg_block2.0.conv1.bias',\n",
    "                      'backbone.vgg_block2.0.conv2.weight', 'backbone.vgg_block2.0.conv2.bias', 'backbone.vgg_block3.0.conv1.weight',\n",
    "                      'backbone.vgg_block3.0.conv1.bias', 'backbone.vgg_block3.0.conv2.weight', 'backbone.vgg_block3.0.conv2.bias',\n",
    "                      'backbone.vgg_block3.0.conv3.weight', 'backbone.vgg_block3.0.conv3.bias', 'backbone.vgg_block4.0.conv1.weight',\n",
    "                      'backbone.vgg_block4.0.conv1.bias', 'backbone.vgg_block4.0.conv2.weight', 'backbone.vgg_block4.0.conv2.bias',\n",
    "                      'backbone.vgg_block4.0.conv3.weight', 'backbone.vgg_block4.0.conv3.bias', 'backbone.vgg_block5.0.conv1.weight',\n",
    "                      'backbone.vgg_block5.0.conv1.bias', 'backbone.vgg_block5.0.conv2.weight', 'backbone.vgg_block5.0.conv2.bias',\n",
    "                      'backbone.vgg_block5.0.conv3.weight', 'backbone.vgg_block5.0.conv3.bias',\n",
    "                     'proposal_generator.rpn_head.conv.weight','proposal_generator.rpn_head.conv.bias',\n",
    "                    'proposal_generator.rpn_head.objectness_logits.weight','proposal_generator.rpn_head.objectness_logits.bias',\n",
    "                    'proposal_generator.rpn_head.anchor_deltas.weight','proposal_generator.rpn_head.anchor_deltas.bias',\n",
    "                    'roi_heads.box_head.fc1.weight','roi_heads.box_head.fc1.bias',\n",
    "                    'roi_heads.box_head.fc2.weight','roi_heads.box_head.fc2.bias',\n",
    "                    'roi_heads.box_predictor.cls_score.weight','roi_heads.box_predictor.cls_score.bias',\n",
    "                    'roi_heads.box_predictor.bbox_pred.weight','roi_heads.box_predictor.bbox_pred.bias']\n",
    "    assert len(dict_map_pth) == len(dict_map_model)\n",
    "    state_dict_new = {}\n",
    "    for i in range(len(dict_map_pth)):\n",
    "        print(dict_map_pth[i])\n",
    "        #print(state_dict[dict_map_pth[i]])\n",
    "        state_dict_new['{}'.format(dict_map_model[i])] = state_dict['{}'.format(dict_map_pth[i])]\n",
    "#     self.load_state_dict({k: v for k, v in state_dict_new.items() if\n",
    "#                           k in self.state_dict()}, strict=False)\n",
    "    torch.save(state_dict_new, new_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "id": "a0351fb2",
   "metadata": {},
   "source": [
    "model_path= \"models/multi_ck_FedAvg/faster_rcnn_multi_ck_AVG_2.pth\"\n",
    "old_model = torch.load(model_path)\n",
    "my_old_model = old_model['model']\n",
    "convert_old_frcnn(my_old_model,\"tmp.pth\")\n",
    "\n",
    "#old_model['model']['RCNN_base.0.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e68e716",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Trainer.build_model(cfg)\n",
    "DetectionCheckpointer(model, save_dir=cfg.OUTPUT_DIR).resume_or_load(\n",
    "                cfg.MODEL.WEIGHTS, resume=args.resume\n",
    "    )\n",
    "res = Trainer.test(cfg, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203b4617",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detectron2",
   "language": "python",
   "name": "detectron2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
